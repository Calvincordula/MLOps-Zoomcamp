{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad378c2",
   "metadata": {},
   "source": [
    "### Reading the data for January 2023 and determining the number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e09421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9be6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in January dataset: 19\n"
     ]
    }
   ],
   "source": [
    "# Load January dataset\n",
    "df_jan = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "df_jan.head()\n",
    "\n",
    "# Determining the number of columns\n",
    "jan_columns = len(df_jan.columns)\n",
    "print(f\"Number of columns in January dataset: {jan_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78053a6",
   "metadata": {},
   "source": [
    "### Computing the duration variable and its standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8dd38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of the trips duration in January: 42.59 minutes\n"
     ]
    }
   ],
   "source": [
    "# Computing the duration variable - difference between pickup & dropoff instances\n",
    "df_jan[\"tpep_pickup_datetime\"] = pd.to_datetime(df_jan['tpep_pickup_datetime'])\n",
    "df_jan[\"tpep_dropoff_datetime\"] = pd.to_datetime(df_jan['tpep_dropoff_datetime'])\n",
    "\n",
    "df_jan[\"duration_minutes\"] = (df_jan[\"tpep_dropoff_datetime\"] - df_jan[\"tpep_pickup_datetime\"]).dt.total_seconds()/60\n",
    "\n",
    "\n",
    "# Standard deviation of trip duration\n",
    "standard_dev = df_jan[\"duration_minutes\"].std()\n",
    "print(f\"The standard deviation of the trips duration in January: {standard_dev:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc1beb",
   "metadata": {},
   "source": [
    "### Removing outliers and computing the fraction of records left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19aeeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of records left after dropping the outliers: 98%\n"
     ]
    }
   ],
   "source": [
    "# Filtering outliers and keeping only records where the duration was between 1 and 60 minutes (inclusive)\n",
    "df_jan_filter = df_jan[(df_jan[\"duration_minutes\"] >= 1) & (df_jan[\"duration_minutes\"] <= 60)]\n",
    "df_jan_rem = len(df_jan_filter)/len(df_jan)\n",
    "print(f\"Fraction of records left after dropping the outliers: {df_jan_rem:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956cb3c5",
   "metadata": {},
   "source": [
    "### One-hot encoding pickup and dropoff location IDs and creating feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7722c9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of this matrix (number of columns): 2 columns\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries\n",
    "records = df_jan_filter[[\"PULocationID\", \"DOLocationID\"]].to_dict(orient=\"records\")\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "feature_matrix = vectorizer.fit_transform(records)\n",
    "\n",
    "# Get the dimensionality (number of columns) of the feature matrix\n",
    "num_features = feature_matrix.shape[1]\n",
    "print(f\"Dimensionality of this matrix (number of columns): {num_features} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b721a",
   "metadata": {},
   "source": [
    "### Training linear regression model and calculating RMSE on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa434ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training data: 9.84\n"
     ]
    }
   ],
   "source": [
    "# Training a Linear Regression Model\n",
    "X_train = feature_matrix\n",
    "y_train = df_jan_filter[\"duration_minutes\"]\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculating RMSE on the training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "print(f\"RMSE on training data: {rmse_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1307898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ad8ca0",
   "metadata": {},
   "source": [
    "### Applying the model to the February 2023 dataset and calculating RMSE on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0f2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22748/371994082.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_feb_filter = df_feb[(df_jan[\"duration_minutes\"] >= 1) & (df_jan[\"duration_minutes\"] <= 60)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on validation data: 9.93\n"
     ]
    }
   ],
   "source": [
    "# Load February dataset\n",
    "df_feb = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')\n",
    "\n",
    "df_feb.head()\n",
    "\n",
    "# Convert pickup and dropoff datetime to datetime objects\n",
    "df_feb[\"tpep_pickup_datetime\"] = pd.to_datetime(df_jan['tpep_pickup_datetime'])\n",
    "df_feb[\"tpep_dropoff_datetime\"] = pd.to_datetime(df_jan['tpep_dropoff_datetime'])\n",
    "df_feb[\"duration_minutes\"] = (df_jan[\"tpep_dropoff_datetime\"] - df_jan[\"tpep_pickup_datetime\"]).dt.total_seconds()/60\n",
    "\n",
    "# Filtering outliers in February dataset\n",
    "df_feb_filter = df_feb[(df_jan[\"duration_minutes\"] >= 1) & (df_jan[\"duration_minutes\"] <= 60)]\n",
    "df_feb_rem = len(df_feb_filter)/len(df_feb)\n",
    "\n",
    "\n",
    "#####\n",
    "# One-hot encode and get feature matrix for February dataset\n",
    "# Create a list of dictionaries\n",
    "records = df_feb_filter[[\"PULocationID\", \"DOLocationID\"]].to_dict(orient=\"records\")\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "feature_matrix = vectorizer.fit_transform(records)\n",
    "\n",
    "# Get the dimensionality (number of columns) of the feature matrix\n",
    "num_features = feature_matrix.shape[1]\n",
    "\n",
    "#Training a Linear Regression Model\n",
    "X_train = feature_matrix\n",
    "y_train = df_feb_filter[\"duration_minutes\"]\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "rmse_val = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "print(f\"RMSE on validation data: {rmse_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533f976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a3139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14212b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd38978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Linear Regression Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X_train = feature_matrix\n",
    "y_train = df_feb_filter[\"duration_minutes\"]\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "rmse_val = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "\n",
    "print(f\"RMSE on validation data: {rmse_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13162cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the February data using the fitted dictionary vectorizer\n",
    "X_val = vectorizer.transform(records)\n",
    "\n",
    "# The response variable for validation\n",
    "y_val = df_feb_filter['duration_minutes'].values\n",
    "\n",
    "# Predict on the validation data\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "print(f\"RMSE on validation data: {rmse_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Load January dataset and determine the number of columns\n",
    "df_jan = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "df_jan.head()\n",
    "jan_columns = len(df_jan.columns)\n",
    "print(f\"Number of columns in January dataset: {jan_columns}\")\n",
    "\n",
    "# Computing the duration and calculating standard deviation\n",
    "df_jan[\"tpep_pickup_datetime\"] = pd.to_datetime(df_jan['tpep_pickup_datetime'])\n",
    "df_jan[\"tpep_dropoff_datetime\"] = pd.to_datetime(df_jan['tpep_dropoff_datetime'])\n",
    "df_jan[\"duration_minutes\"] = (df_jan[\"tpep_dropoff_datetime\"] - df_jan[\"tpep_pickup_datetime\"]).dt.total_seconds()/60\n",
    "\n",
    "standard_dev = df_jan[\"duration_minutes\"].std()\n",
    "print(f\"The standard deviation of the trips duration in January: {standard_dev:.2f} minutes\")\n",
    "\n",
    "# Filtering outliers and keeping only records where the duration was between 1 and 60 minutes (inclusive)\n",
    "df_jan_filter = df_jan[(df_jan[\"duration_minutes\"] >= 1) & (df_jan[\"duration_minutes\"] <= 60)]\n",
    "df_jan_rem = len(df_jan_filter)/len(df_jan)\n",
    "print(f\"Fraction of records left after dropping the outliers: {df_jan_rem:.0%}\")\n",
    "\n",
    "# One-hot encode pickup and dropoff location IDs and get feature matrix\n",
    "\n",
    "# Create a list of dictionaries\n",
    "records = df_jan_filter[[\"PULocationID\", \"DOLocationID\"]].to_dict(orient=\"records\")\n",
    "# Fit a dictionary vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "feature_matrix = vectorizer.fit_transform(records)\n",
    "# Get the dimensionality (number of columns) of the feature matrix\n",
    "num_features = feature_matrix.shape[1]\n",
    "print(f\"Dimensionality of this matrix (number of columns): {num_features} columns\")\n",
    "\n",
    "# Training linear regression model and calculating RMSE on training data\n",
    "X_train = feature_matrix\n",
    "y_train = df_jan_filter[\"duration_minutes\"]\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Calculate RMSE on the training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "print(f\"RMSE on training data: {rmse_train:.2f}\")\n",
    "\n",
    "# Applying the model to the February 2023 dataset and calculating RMSE on validation\n",
    "# Load February dataset and apply the model to validation dataset\n",
    "df_feb = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')\n",
    "df_feb.head()\n",
    "# Convert pickup and dropoff datetime to datetime objects\n",
    "df_feb[\"tpep_pickup_datetime\"] = pd.to_datetime(df_jan['tpep_pickup_datetime'])\n",
    "df_feb[\"tpep_dropoff_datetime\"] = pd.to_datetime(df_jan['tpep_dropoff_datetime'])\n",
    "df_feb[\"duration_minutes\"] = (df_jan[\"tpep_dropoff_datetime\"] - df_jan[\"tpep_pickup_datetime\"]).dt.total_seconds()/60\n",
    "\n",
    "# Calculating standard deviation of trip duration in February\n",
    "standard_dev = df_feb[\"duration_minutes\"].std()\n",
    "print(f\"The standard deviation of the trips duration in January: {standard_dev:.2f} minutes\")\n",
    "\n",
    "# Filtering outliers in February dataset\n",
    "df_feb_filter = df_feb[(df_jan[\"duration_minutes\"] >= 1) & (df_jan[\"duration_minutes\"] <= 60)]\n",
    "df_feb_rem = len(df_feb_filter)/len(df_feb)\n",
    "print(f\"Fraction of records left after dropping the outliers: {df_feb_rem:.0%}\")\n",
    "\n",
    "# One-hot encode and get feature matrix for February dataset\n",
    "# Create a list of dictionaries\n",
    "records = df_feb_filter[[\"PULocationID\", \"DOLocationID\"]].to_dict(orient=\"records\")\n",
    "\n",
    "# Fit a dictionary vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "feature_matrix = vectorizer.fit_transform(records)\n",
    "\n",
    "# Get the dimensionality (number of columns) of the feature matrix\n",
    "num_features = feature_matrix.shape[1]\n",
    "\n",
    "print(f\"Dimensionality of this matrix (number of columns): {num_features} columns\")\n",
    "\n",
    "X_train = feature_matrix\n",
    "y_train = df_feb_filter[\"duration_minutes\"]\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate RMSE on the training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "rmse_val = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "\n",
    "print(f\"RMSE on validation data: {rmse_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d4af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d027aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
